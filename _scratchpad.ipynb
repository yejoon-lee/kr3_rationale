{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwittgensteinian\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/research/wandb/run-20220505_120242-2fzxbfjn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/wittgensteinian/research/runs/2fzxbfjn\" target=\"_blank\">light-nexu-4</a></strong> to <a href=\"https://wandb.ai/wittgensteinian/research\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load wandb artifact (trained model state)\n",
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('wittgensteinian/Parameter-Efficient-Tuning/LoRA_BERT:v0', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'requests' has no attribute 'exceptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEntryNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py:486\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=484'>485</a>\u001b[0m r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mhead(url, headers\u001b[39m=\u001b[39mheaders, allow_redirects\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, proxies\u001b[39m=\u001b[39mproxies, timeout\u001b[39m=\u001b[39metag_timeout)\n\u001b[0;32m--> <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=485'>486</a>\u001b[0m _raise_for_status(r)\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=486'>487</a>\u001b[0m etag \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mX-Linked-Etag\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mETag\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py:409\u001b[0m, in \u001b[0;36m_raise_for_status\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=407'>408</a>\u001b[0m \u001b[39melif\u001b[39;00m error_code \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mEntryNotFound\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=408'>409</a>\u001b[0m     \u001b[39mraise\u001b[39;00m EntryNotFoundError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m404 Client Error: Entry Not Found for url: \u001b[39m\u001b[39m{\u001b[39;00mrequest\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=409'>410</a>\u001b[0m \u001b[39melif\u001b[39;00m error_code \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRevisionNotFound\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m: 404 Client Error: Entry Not Found for url: https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/gsdsaml/kr3_rationale/_scratchpad.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22534e552d47534453227d/home/gsdsaml/kr3_rationale/_scratchpad.ipynb#ch0000001vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m BertForSequenceClassification, BertTokenizer\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22534e552d47534453227d/home/gsdsaml/kr3_rationale/_scratchpad.ipynb#ch0000001vscode-remote?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m BertForSequenceClassification\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mbert-base-multilingual-cased\u001b[39m\u001b[39m'\u001b[39m, num_labels\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22534e552d47534453227d/home/gsdsaml/kr3_rationale/_scratchpad.ipynb#ch0000001vscode-remote?line=3'>4</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m BertTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m'\u001b[39;49m\u001b[39mbert-base-multilingual-cased\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1719\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1716'>1717</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1717'>1718</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1718'>1719</a>\u001b[0m         resolved_vocab_files[file_id] \u001b[39m=\u001b[39m cached_path(\n\u001b[1;32m   <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1719'>1720</a>\u001b[0m             file_path,\n\u001b[1;32m   <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1720'>1721</a>\u001b[0m             cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1721'>1722</a>\u001b[0m             force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1722'>1723</a>\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1723'>1724</a>\u001b[0m             resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1724'>1725</a>\u001b[0m             local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1725'>1726</a>\u001b[0m             use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1726'>1727</a>\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1727'>1728</a>\u001b[0m         )\n\u001b[1;32m   <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1729'>1730</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m   <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1730'>1731</a>\u001b[0m         \u001b[39mif\u001b[39;00m local_files_only:\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py:282\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=277'>278</a>\u001b[0m     local_files_only \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=279'>280</a>\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=280'>281</a>\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=281'>282</a>\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=282'>283</a>\u001b[0m         url_or_filename,\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=283'>284</a>\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=284'>285</a>\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=285'>286</a>\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=286'>287</a>\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=287'>288</a>\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=288'>289</a>\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=289'>290</a>\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=290'>291</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=291'>292</a>\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=292'>293</a>\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=293'>294</a>\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py:502\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=498'>499</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m300\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mstatus_code \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m399\u001b[39m:\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=499'>500</a>\u001b[0m         url_to_download \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mheaders[\u001b[39m\"\u001b[39m\u001b[39mLocation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=500'>501</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (\n\u001b[0;32m--> <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=501'>502</a>\u001b[0m     requests\u001b[39m.\u001b[39;49mexceptions\u001b[39m.\u001b[39mSSLError,\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=502'>503</a>\u001b[0m     requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mProxyError,\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=503'>504</a>\u001b[0m     RepositoryNotFoundError,\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=504'>505</a>\u001b[0m     EntryNotFoundError,\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=505'>506</a>\u001b[0m     RevisionNotFoundError,\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=506'>507</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=507'>508</a>\u001b[0m     \u001b[39m# Actually raise for those subclasses of ConnectionError\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=508'>509</a>\u001b[0m     \u001b[39m# Also raise the custom errors coming from a non existing repo/branch/file as they are caught later on.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=509'>510</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=510'>511</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (HTTPError, requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mConnectionError, requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout):\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=511'>512</a>\u001b[0m     \u001b[39m# Otherwise, our Internet connection is down.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/gsdsaml/miniconda3/envs/cuda11.3/lib/python3.8/site-packages/transformers/utils/hub.py?line=512'>513</a>\u001b[0m     \u001b[39m# etag is None\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'requests' has no attribute 'exceptions'"
     ]
    }
   ],
   "source": [
    "# load base model and tokenizer\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune\n",
    "model.load_state_dict(torch.load('artifacts/finetuned_BERT:v7/summer-sea-11.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kr3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adapter\n",
    "model.load_adapter('artifacts/Adapter_BERT:v5/kr3', set_active=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['bert.embeddings.position_ids', 'bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias'], unexpected_keys=['bert.encoder.layer.0.attention.self.query.lora_A', 'bert.encoder.layer.0.attention.self.query.lora_B', 'bert.encoder.layer.0.attention.self.value.lora_A', 'bert.encoder.layer.0.attention.self.value.lora_B', 'bert.encoder.layer.1.attention.self.query.lora_A', 'bert.encoder.layer.1.attention.self.query.lora_B', 'bert.encoder.layer.1.attention.self.value.lora_A', 'bert.encoder.layer.1.attention.self.value.lora_B', 'bert.encoder.layer.2.attention.self.query.lora_A', 'bert.encoder.layer.2.attention.self.query.lora_B', 'bert.encoder.layer.2.attention.self.value.lora_A', 'bert.encoder.layer.2.attention.self.value.lora_B', 'bert.encoder.layer.3.attention.self.query.lora_A', 'bert.encoder.layer.3.attention.self.query.lora_B', 'bert.encoder.layer.3.attention.self.value.lora_A', 'bert.encoder.layer.3.attention.self.value.lora_B', 'bert.encoder.layer.4.attention.self.query.lora_A', 'bert.encoder.layer.4.attention.self.query.lora_B', 'bert.encoder.layer.4.attention.self.value.lora_A', 'bert.encoder.layer.4.attention.self.value.lora_B', 'bert.encoder.layer.5.attention.self.query.lora_A', 'bert.encoder.layer.5.attention.self.query.lora_B', 'bert.encoder.layer.5.attention.self.value.lora_A', 'bert.encoder.layer.5.attention.self.value.lora_B', 'bert.encoder.layer.6.attention.self.query.lora_A', 'bert.encoder.layer.6.attention.self.query.lora_B', 'bert.encoder.layer.6.attention.self.value.lora_A', 'bert.encoder.layer.6.attention.self.value.lora_B', 'bert.encoder.layer.7.attention.self.query.lora_A', 'bert.encoder.layer.7.attention.self.query.lora_B', 'bert.encoder.layer.7.attention.self.value.lora_A', 'bert.encoder.layer.7.attention.self.value.lora_B', 'bert.encoder.layer.8.attention.self.query.lora_A', 'bert.encoder.layer.8.attention.self.query.lora_B', 'bert.encoder.layer.8.attention.self.value.lora_A', 'bert.encoder.layer.8.attention.self.value.lora_B', 'bert.encoder.layer.9.attention.self.query.lora_A', 'bert.encoder.layer.9.attention.self.query.lora_B', 'bert.encoder.layer.9.attention.self.value.lora_A', 'bert.encoder.layer.9.attention.self.value.lora_B', 'bert.encoder.layer.10.attention.self.query.lora_A', 'bert.encoder.layer.10.attention.self.query.lora_B', 'bert.encoder.layer.10.attention.self.value.lora_A', 'bert.encoder.layer.10.attention.self.value.lora_B', 'bert.encoder.layer.11.attention.self.query.lora_A', 'bert.encoder.layer.11.attention.self.query.lora_B', 'bert.encoder.layer.11.attention.self.value.lora_A', 'bert.encoder.layer.11.attention.self.value.lora_B'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lora\n",
    "# strict set to False because we only load the LoRA matrices.\n",
    "model.load_state_dict(torch.load('artifacts/LoRA_BERT:v0/LoRA-8.pth', map_location=torch.device('cpu')), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current transformer package is vanilla transformer.\n"
     ]
    }
   ],
   "source": [
    "# env check\n",
    "import transformers\n",
    "if 'AdapterConfig' in dir(transformers):\n",
    "    print('Current transformer package is adapter-transformer.')\n",
    "else:\n",
    "    print('Current transformer package is vanilla transformer.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Wittgensteinian--KR3-9f7e41b8ab859e44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset parquet/Wittgensteinian--KR3 to /home/vscode/.cache/huggingface/datasets/parquet/Wittgensteinian--KR3-9f7e41b8ab859e44/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e9941749e84359b06c3e0162612b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940cf3222d19427c9d2b460003f9fef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/120M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819cccb11e974e1fbe39822c34fe9881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/vscode/.cache/huggingface/datasets/parquet/Wittgensteinian--KR3-9f7e41b8ab859e44/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "kr3 = load_dataset(\"Wittgensteinian/KR3\", name='kr3', split='train')\n",
    "kr3 = kr3.remove_columns(['__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example input and forward pass\n",
    "i = 1231\n",
    "review = kr3['Review'][i:i+1]\n",
    "true_label = kr3['Rating'][i:i+1]\n",
    "tokenized = tokenizer(review)\n",
    "input_tensors = {k:torch.tensor(v) for k,v in tokenized.items()}\n",
    "output = model(**input_tensors, output_attentions=True) # outputs.attention is a tuple, each entry a 4D attn tensor for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['무료주차된다. 반찬이 맛있담. 주차 발레 해준다. 식사시간에 대기 줄어 길다']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review natural text\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Predict:', tensor(1), 'True:', [1])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference result\n",
    "'Predict:', output.logits.argmax(), 'True:', true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 12, 33, 33])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full attention weights\n",
    "attn_weights = torch.stack([attn for attn in output.attentions], dim=1)\n",
    "attn_weights.size() # (batch_size, num_layers, num_heads, seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1008 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# heatmap for full attn map, mean over head\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(25,14))\n",
    "l = -4 # last layer, or 4th layer from the back?\n",
    "sns.heatmap(attn_weights[0,l,:,:,:].mean(0).detach().numpy(), ax=ax) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33])\n"
     ]
    }
   ],
   "source": [
    "# per-token attn weight indexing following Chrysostomou et al., 2021 and Jain et al., 2020\n",
    "# see src/models/bert.py line 71 in https://github.com/GChrysostomou/saloss\n",
    "\n",
    "attention = attn_weights[0,-4,:,0,:].mean(0).detach() # layer, mean over head, attn w.r.t. <CLS>\n",
    "print(attention.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0352, 0.0387, 0.0476, 0.0181, 0.0189, 0.0243, 0.0514, 0.0302, 0.0386,\n",
       "        0.0242, 0.0494, 0.0538, 0.0375, 0.0288, 0.0312, 0.0263, 0.0228, 0.0202,\n",
       "        0.0110, 0.0143, 0.0200, 0.0484, 0.0353, 0.0246, 0.0362, 0.0256, 0.0284,\n",
       "        0.0252, 0.0256, 0.0097, 0.0145, 0.0147, 0.0690])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention # per token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude special tokens: [CLS]-101, [SEP]-102, [PAD]-0\n",
    "\n",
    "# assert\n",
    "assert len(tokenized['input_ids'][0]) == len(attention)\n",
    "\n",
    "# bool array for mask\n",
    "special_token_mask = torch.zeros_like(attention).bool()\n",
    "\n",
    "# iterate over each tokens. If token is one of special tokens, change the mask value.\n",
    "special_tokens = [0, 101, 102]\n",
    "for i, input_id in enumerate(tokenized['input_ids']):\n",
    "    if input_id in special_tokens:\n",
    "        special_token_mask[i] = 1\n",
    "\n",
    "# normalize over unmasked tokens\n",
    "attention = torch.masked_fill(attention, special_token_mask, 0)\n",
    "attention /= attention.sum(dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0352, 0.0387, 0.0476, 0.0181, 0.0189, 0.0243, 0.0514, 0.0302, 0.0386,\n",
       "        0.0242, 0.0494, 0.0538, 0.0375, 0.0288, 0.0312, 0.0263, 0.0228, 0.0202,\n",
       "        0.0110, 0.0143, 0.0200, 0.0484, 0.0353, 0.0246, 0.0362, 0.0256, 0.0284,\n",
       "        0.0252, 0.0256, 0.0097, 0.0145, 0.0147, 0.0690])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention # per token, normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention score per word, computed by summing scores for tokens in the word\n",
    "words = review[0].split(' ')\n",
    "attention_per_word = torch.zeros(len(words))\n",
    "tokens_per_word = []\n",
    "\n",
    "# start slicing index by 1\n",
    "# why not 0? Because first token is the [CLS]. cf) We don't have [SEP] in the middle of the input, so we do not consider that.\n",
    "i = 1\n",
    "\n",
    "for j, word in enumerate(words):\n",
    "    # number of tokens in the word\n",
    "    num_tokens = len(tokenizer.tokenize(word))\n",
    "\n",
    "    # slice the attention by num_tokens\n",
    "    tokens_per_word.append(attention[i:i+num_tokens])\n",
    "    # sum over tokens to obtain attention per word\n",
    "    sum = tokens_per_word[j].sum(dim=-1)\n",
    "    attention_per_word[j] = sum\n",
    "    i += num_tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1991, 0.0930, 0.1695, 0.0575, 0.0431, 0.0937, 0.1218, 0.0536, 0.0353,\n",
       "        0.0293])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_per_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERASER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = 0.2\n",
    "rationale_idxs = attention_per_word.argsort(descending=True)[:int(len(attention_per_word)*ratio)]\n",
    "rationale_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['무료주차된다. 반찬이 맛있담. 주차 발레 해준다. 식사시간에 대기 줄어 길다']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "rationale = [] # words in the rationale, ordered (for sufficiency eval)\n",
    "unrationale = [] # words not in the rationale, ordered (for completeness evla)\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    if i in rationale_idxs:\n",
    "        rationale.append(word)\n",
    "    else:\n",
    "        unrationale.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "무료주차된다. 맛있담. \n",
      "\n",
      "반찬이 주차 발레 해준다. 식사시간에 대기 줄어 길다 \n",
      "\n",
      "['무료주차된다. 반찬이 맛있담. 주차 발레 해준다. 식사시간에 대기 줄어 길다']\n"
     ]
    }
   ],
   "source": [
    "rationale_text = ' '.join(rationale) # words in the list concated to a sentence\n",
    "unrationale_text = ' '.join(unrationale)\n",
    "\n",
    "print(rationale_text, '\\n')\n",
    "print(unrationale_text, '\\n')\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992024302482605"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_rationale = tokenizer(rationale_text)\n",
    "input_tensors = {k:torch.tensor([v]) for k,v in tokenized_rationale.items()} # [v] for pseudo-batch\n",
    "rationale_output = model(**input_tensors, output_attentions=True)\n",
    "rationale_prediction = torch.softmax(rationale_output.logits.detach(), dim=-1)[0][1].item()\n",
    "rationale_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9740928411483765"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_unrationale = tokenizer(unrationale_text)\n",
    "input_tensors = {k:torch.tensor([v]) for k,v in tokenized_unrationale.items()} # [v] for pseudo-batch\n",
    "unrationale_output = model(**input_tensors, output_attentions=True)\n",
    "unrationale_prediction = torch.softmax(unrationale_output.logits.detach(), dim=-1)[0][1].item()\n",
    "unrationale_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991903901100159"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_prediction = torch.softmax(output.logits.detach(), dim=-1)[0][1].item()\n",
    "original_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.detach().size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Flip (Serrano & Smith 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_prediction = output.logits.argmax().item()\n",
    "original_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(211)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.argsort(descending=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision flipped at 0.9954545454545455, 219/220\n"
     ]
    }
   ],
   "source": [
    "for i in range(attention.size(-1)):\n",
    "    zeroed_idxs = attention.argsort(descending=True)[:i+1] # zero the top i tokens\n",
    "    \n",
    "    # rebuild input in which some of the tokens are zeroed.\n",
    "    flip_tokenized = {}\n",
    "    for key, value in tokenized.items(): # keys are 'input_ids', 'token_type_ids', and 'attention_mask'\n",
    "        new_value = []\n",
    "        for i, x in enumerate(value): \n",
    "            if i not in zeroed_idxs:\n",
    "                new_value.append(x)\n",
    "        flip_tokenized[key] = new_value\n",
    "\n",
    "    # forward\n",
    "    flip_output = model(**{k:torch.tensor([v]) for k,v in flip_tokenized.items()})\n",
    "    if original_prediction != flip_output.logits.argmax().item():\n",
    "        print(f\"Decision flipped at {i/attention.size(-1)}, {i}/{attention.size(-1)}\")\n",
    "        break\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5333f1ae2d2dec2c1d8a5fd16a6937e3d6f1660c2626f76e133a4bcfc7001c97"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('cuda11.3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
